{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num text: 63\n",
      "num link: 63\n",
      "Found duplicate at : ['2', '52', '40', '26', '51', '46', '16', '21', '35', '7']\n",
      "Before removing duplicates, we have 63 rows.\n",
      "After removing duplicates, we have 42 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['2', '52', '40', '15', '51', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 43 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '35', '47', '41', '21', '13', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '47', '41', '16', '21', '35', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['27', '7', '15', '47', '41', '36', '3', '22']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 53 rows.\n",
      "num text: 63\n",
      "num link: 63\n",
      "Found duplicate at : ['2', '52', '40', '26', '51', '46', '12', '21', '35', '7']\n",
      "Before removing duplicates, we have 63 rows.\n",
      "After removing duplicates, we have 42 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 63\n",
      "num link: 63\n",
      "Found duplicate at : ['2', '52', '40', '26', '51', '15', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 63 rows.\n",
      "After removing duplicates, we have 42 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['2', '52', '40', '51', '14', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 43 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '47', '41', '12', '21', '35', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '15', '47', '41', '36', '21', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['27', '7', '47', '14', '41', '36', '3', '22']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 53 rows.\n",
      "num text: 63\n",
      "num link: 63\n",
      "Found duplicate at : ['2', '52', '40', '26', '51', '46', '16', '21', '35', '7']\n",
      "Before removing duplicates, we have 63 rows.\n",
      "After removing duplicates, we have 42 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['2', '52', '40', '51', '14', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 43 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '35', '47', '41', '21', '13', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '47', '41', '16', '21', '35', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 60\n",
      "num link: 60\n",
      "Found duplicate at : ['3', '14', '47', '41', '36', '21', '7']\n",
      "Before removing duplicates, we have 60 rows.\n",
      "After removing duplicates, we have 45 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 64\n",
      "num link: 64\n",
      "Found duplicate at : ['27', '7', '53', '52', '47', '41', '36', '3', '13', '22']\n",
      "Before removing duplicates, we have 64 rows.\n",
      "After removing duplicates, we have 43 rows.\n",
      "After cleaning, we have 53 rows.\n",
      "num text: 63\n",
      "num link: 63\n",
      "Found duplicate at : ['2', '52', '40', '26', '51', '15', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 63 rows.\n",
      "After removing duplicates, we have 42 rows.\n",
      "After cleaning, we have 52 rows.\n",
      "num text: 62\n",
      "num link: 62\n",
      "Found duplicate at : ['13', '2', '52', '40', '51', '46', '21', '35', '7']\n",
      "Before removing duplicates, we have 62 rows.\n",
      "After removing duplicates, we have 43 rows.\n",
      "After cleaning, we have 52 rows.\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.boxofficemojo.com\"\n",
    "for year in range(2000, 2019):\n",
    "    page = requests.get(\"https://www.boxofficemojo.com/weekend/by-year/{}/\".format(year))\n",
    "    bs = BeautifulSoup(page.text)\n",
    "    rows = bs.findAll(\n",
    "        \"tr\"\n",
    "    )\n",
    "    # 1. Weekend date\n",
    "    # 2. Top 10 Gross\n",
    "    # 3. Top 10 Gross % change\n",
    "    # 4. Overall Gross\n",
    "    # 5. Overall Gross % change\n",
    "    # 6. Num Releases\n",
    "    # 7. #1 Release\n",
    "    # 8. Week Num\n",
    "    text_in_rows = [\n",
    "        [elem.text for elem in row.findAll(\"td\") if not elem.text == \"-\"]\n",
    "        for row in rows \n",
    "    #     if len(row.findAll(\"td\")) > 0\n",
    "    ]\n",
    "    # 1. Weekend Link\n",
    "    # 2. Top Performing Movie Link\n",
    "    links_in_rows = [\n",
    "        [base_url + elem.get('href') for elem in row.findAll(\"a\")][0:2]\n",
    "        for row in rows\n",
    "    ]\n",
    "    text_in_rows.pop(0)\n",
    "    links_in_rows.pop(0)\n",
    "    print(\"num text: {}\\nnum link: {}\".format(len(text_in_rows), len(links_in_rows)))\n",
    "    for ii in range(len(text_in_rows)):\n",
    "        text_in_rows[ii].append(links_in_rows[ii][0])\n",
    "        text_in_rows[ii].append(links_in_rows[ii][1])\n",
    "    weekends = [row[7] for row in text_in_rows if len(row) > 0]\n",
    "    duplicates = list(set([x for x in weekends if weekends.count(x) > 1]))\n",
    "    print(\"Found duplicate at : {}\".format(duplicates))\n",
    "    dup_rows = [row for row in text_in_rows if len(row) > 0 if row[7] in duplicates]\n",
    "    print(\"Before removing duplicates, we have {} rows.\".format(len(text_in_rows)))\n",
    "    [text_in_rows.remove(row) for row in dup_rows if len(row) > 0 if row[7] in duplicates]\n",
    "    print(\"After removing duplicates, we have {} rows.\".format(len(text_in_rows)))\n",
    "    cleaned_rows = [row for row in dup_rows if not \"wknd\" in row[0] if not \"Day\" in row[0]]\n",
    "    text_in_rows = text_in_rows + cleaned_rows\n",
    "    print(\"After cleaning, we have {} rows.\".format(len(text_in_rows)))\n",
    "    df = pd.DataFrame(\n",
    "        {\n",
    "            \"weekend\":[row[0] for row in text_in_rows],\n",
    "            \"top10gross\":[int(\"\".join(row[1][1:].split(\",\"))) for row in text_in_rows],\n",
    "            \"top10percentchange\":[\n",
    "                -1*float(row[2][1:-1]) if row[2][0] == \"-\" \n",
    "                else float(row[2][1:-1])\n",
    "                for row in text_in_rows\n",
    "            ],\n",
    "            \"overallgross\":[int(\"\".join(row[3][1:].split(\",\"))) for row in text_in_rows],\n",
    "            \"overallpercentchange\":[\n",
    "                -1*float(row[4][1:-1]) if row[4][0] == \"-\" \n",
    "                else float(row[4][1:-1])\n",
    "                for row in text_in_rows\n",
    "            ],\n",
    "            \"numreleases\":[int(row[5]) for row in text_in_rows],\n",
    "            \"num1release\":[row[6] for row in text_in_rows],\n",
    "            \"weeknum\":[int(row[7]) for row in text_in_rows],\n",
    "            \"weekendlink\":[row[8] for row in text_in_rows],\n",
    "            \"num1link\":[row[9] for row in text_in_rows]\n",
    "        }\n",
    "    )\n",
    "    df = df.sort_values('weeknum')\n",
    "    df.to_csv(\"mojo_{}.csv\".format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num text: 51\n",
      "num link: 51\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.boxofficemojo.com\"\n",
    "year = 2019\n",
    "page = requests.get(\"https://www.boxofficemojo.com/weekend/by-year/{}/\".format(year))\n",
    "bs = BeautifulSoup(page.text)\n",
    "rows = bs.findAll(\n",
    "    \"tr\"\n",
    ")\n",
    "# 1. Weekend date\n",
    "# 2. Top 10 Gross\n",
    "# 3. Top 10 Gross % change\n",
    "# 4. Overall Gross\n",
    "# 5. Overall Gross % change\n",
    "# 6. Num Releases\n",
    "# 7. #1 Release\n",
    "# 8. Week Num\n",
    "text_in_rows = [\n",
    "    [elem.text for elem in row.findAll(\"td\") if not elem.text == \"-\"]\n",
    "    for row in rows \n",
    "#     if len(row.findAll(\"td\")) > 0\n",
    "]\n",
    "# 1. Weekend Link\n",
    "# 2. Top Performing Movie Link\n",
    "links_in_rows = [\n",
    "    [base_url + elem.get('href') for elem in row.findAll(\"a\")][0:2]\n",
    "    for row in rows\n",
    "]\n",
    "text_in_rows.pop(0)\n",
    "links_in_rows.pop(0)\n",
    "print(\"num text: {}\\nnum link: {}\".format(len(text_in_rows), len(links_in_rows)))\n",
    "for ii in range(len(text_in_rows)):\n",
    "    text_in_rows[ii].append(links_in_rows[ii][0])\n",
    "    text_in_rows[ii].append(links_in_rows[ii][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found duplicate at : ['3', '41', '16', '21', '35', '7']\n",
      "Before removing duplicates, we have 51 rows.\n",
      "After removing duplicates, we have 39 rows.\n",
      "After cleaning, we have 45 rows.\n"
     ]
    }
   ],
   "source": [
    "weekends = [row[7] for row in text_in_rows if len(row) > 0]\n",
    "duplicates = list(set([x for x in weekends if weekends.count(x) > 1]))\n",
    "print(\"Found duplicate at : {}\".format(duplicates))\n",
    "dup_rows = [row for row in text_in_rows if len(row) > 0 if row[7] in duplicates]\n",
    "print(\"Before removing duplicates, we have {} rows.\".format(len(text_in_rows)))\n",
    "[text_in_rows.remove(row) for row in dup_rows if len(row) > 0 if row[7] in duplicates]\n",
    "print(\"After removing duplicates, we have {} rows.\".format(len(text_in_rows)))\n",
    "cleaned_rows = [row for row in dup_rows if not \"wknd\" in row[0] if not \"Day\" in row[0]]\n",
    "text_in_rows = text_in_rows + cleaned_rows\n",
    "print(\"After cleaning, we have {} rows.\".format(len(text_in_rows)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(\n",
    "    {\n",
    "        \"weekend\":[row[0] for row in text_in_rows],\n",
    "        \"top10gross\":[int(\"\".join(row[1][1:].split(\",\"))) for row in text_in_rows],\n",
    "        \"top10percentchange\":[\n",
    "            -1*float(row[2][1:-1]) if row[2][0] == \"-\" \n",
    "            else float(row[2][1:-1])\n",
    "            for row in text_in_rows\n",
    "        ],\n",
    "        \"overallgross\":[int(\"\".join(row[3][1:].split(\",\"))) for row in text_in_rows],\n",
    "        \"overallpercentchange\":[\n",
    "            -1*float(row[4][1:-1]) if row[4][0] == \"-\" \n",
    "            else float(row[4][1:-1])\n",
    "            for row in text_in_rows\n",
    "        ],\n",
    "        \"numreleases\":[int(row[5]) for row in text_in_rows],\n",
    "        \"num1release\":[row[6] for row in text_in_rows],\n",
    "        \"weeknum\":[int(row[7]) for row in text_in_rows],\n",
    "        \"weekendlink\":[row[8] for row in text_in_rows],\n",
    "        \"num1link\":[row[9] for row in text_in_rows]\n",
    "    }\n",
    ")\n",
    "df = df.sort_values('weeknum')\n",
    "df.to_csv(\"mojo_{}.csv\".format(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
